<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Late to the AI Party: Lessons from Building LLM Infrastructure | Natalie Villasana</title>
    <meta name="description" content="I left tech to pursue advertising in summer 2022, before AI really took off. During my time as a copywriter, AI tools became widespread seemingly overnight. ...">
    
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/assets/css/main.css">
    
    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    
    <!-- SEO -->
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Late to the AI Party: Lessons from Building LLM Infrastructure | Natalie Villasana</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="Late to the AI Party: Lessons from Building LLM Infrastructure" />
<meta name="author" content="Natalie Villasana" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="I left tech to pursue advertising in summer 2022, before AI really took off. During my time as a copywriter, AI tools became widespread seemingly overnight. Taking on an LLM API project this summer was as much about refreshing my coding skills as it was about demystifying this technology that‚Äôs reshaping our world." />
<meta property="og:description" content="I left tech to pursue advertising in summer 2022, before AI really took off. During my time as a copywriter, AI tools became widespread seemingly overnight. Taking on an LLM API project this summer was as much about refreshing my coding skills as it was about demystifying this technology that‚Äôs reshaping our world." />
<link rel="canonical" href="http://localhost:4000/blog/missed-ai-revolution/" />
<meta property="og:url" content="http://localhost:4000/blog/missed-ai-revolution/" />
<meta property="og:site_name" content="Natalie Villasana" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-08-20T00:00:00-04:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Late to the AI Party: Lessons from Building LLM Infrastructure" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Natalie Villasana"},"dateModified":"2025-08-20T00:00:00-04:00","datePublished":"2025-08-20T00:00:00-04:00","description":"I left tech to pursue advertising in summer 2022, before AI really took off. During my time as a copywriter, AI tools became widespread seemingly overnight. Taking on an LLM API project this summer was as much about refreshing my coding skills as it was about demystifying this technology that‚Äôs reshaping our world.","headline":"Late to the AI Party: Lessons from Building LLM Infrastructure","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blog/missed-ai-revolution/"},"url":"http://localhost:4000/blog/missed-ai-revolution/"}</script>
<!-- End Jekyll SEO tag -->

</head>
<body>
    <div class="blog-container">
    <div class="blog-nav">
        <a href="/" class="back-link">‚Üê Back to Portfolio</a>
    </div>
    
    <header class="blog-header">
        <h1 class="blog-title">Late to the AI Party: Lessons from Building LLM Infrastructure</h1>
        
        <p class="blog-subtitle">What happens when you build AI infrastructure after everyone else already started</p>
        
        <div class="blog-meta">
            
            
            <br><time datetime="2025-08-20T00:00:00-04:00">August 20, 2025</time>
            
        </div>
    </header>

    <div class="blog-content">
        <p>I left tech to pursue advertising in summer 2022, before AI really took off. During my time as a copywriter, AI tools became widespread seemingly overnight. Taking on an LLM API project this summer was as much about refreshing my coding skills as it was about demystifying this technology that‚Äôs reshaping our world.</p>

<h2 id="from-magic-to-reality-check">From Magic to Reality Check</h2>

<p>The first time I used Cursor to write code, my jaw hit the floor. I was genuinely mesmerized watching it generate entire files in seconds. But nothing could‚Äôve snapped me out of it faster than Claude trying to hardcode database auth into a docker compose file. It was a moment that perfectly captured AI‚Äôs unique way of oscillating between the self-assured troubleshooting of a senior engineer to some kind of summer intern from hell.</p>

<p>(I just learned what vibe coding is this week by the way ‚Äì a new approach where developers use AI tools to generate code based on natural language prompts. In other words, based on ‚Äúvibes.‚Äù It sounds misleadingly calm and laidback, but at least in my experience, coding with agents has more of a ‚Äúyou‚Äôre a helicopter parent to a robot‚Äù type vibe than the ‚Äúfeet on the desk chillin‚Äô‚Äù vibe I expected.)</p>

<h2 id="cpu-only-llms-when-sluggishness-is-part-of-the-charm">CPU-Only LLMs: When Sluggishness is Part of the Charm</h2>

<p>For my LLM project, I wanted to understand the fundamentals without breaking the bank. I chose Hetzner for hosting and looked into CPU-only models. Part of the appeal of self-hosting your own LLM is that you can have chats without your data going to Google or OpenAI. But despite legitimate concerns about privacy, the vast majority of people have no option but use the major AI tools like ChatGPT, CoPilot, Gemini, etc. Their dominance in the market, and therefore convenience factor ‚Äì not to mention the technical and economic hurdles of setting up your own private model ‚Äì mean that privacy, as usual, is forced to take a back seat to practicality.</p>

<p>That said, the prevalence of mainstream tools doesn‚Äôt mean innovation or alternatives are out of reach. At the end of the day, experimenting and imagining new ways of doing things is what engineering is all about. While my app is charmingly unusable in its slowness, I built the infrastructure so one could easily switch out the models, inference engine, and hosting environment. It was an exercise in understanding how these applications actually work.</p>

<h2 id="demystifying-the-components">Demystifying the Components</h2>

<p><strong>A LLM</strong> (Large Language Model) is like a master chef who has trained by tasting thousands of dishes and internalized patterns of what makes food delicious.</p>

<p>In reality, a model is just a giant file of numbers ‚Äì millions or billions of numerical parameters encoding everything learned during training.</p>

<p><strong>Inference</strong> is using the model to answer questions, generate images, etc. Inference is the actual cooking process. When you ask the model to generate text, it uses those learned patterns to make decisions.</p>

<p>The <strong>inference engine</strong> is the kitchen itself: the computational environment that makes it possible for our chef to get to work.</p>

<p>It wasn‚Äôt until I saw the price tags on the GCP Compute Engine page for GPU-resourced VMs that I began to understand just how much power LLMs need ‚Äì even on a small scale!</p>

<p>I had been researching ratings and reviews of different models, was hearing good things about the model Mistral 7b, and was planning on using it for my app.</p>

<p>Then I learned that a ‚Äúbudget‚Äù or smaller version of Mistral 7b would still require ~8-12 GB of VRAM (dedicated GPU memory) to function properly. And I learned that an AWS instance that could support that could run you upwards of $300/month.</p>

<p>That‚Äôs for a smaller version of Mistral 7b, mind you, where its inference is scaled down. The ‚ÄúMid-tier GPU inference‚Äù ‚Äì the FP16 version ‚Äì would require ~24GB of VRAM for smooth inference. Which could run you upwards of $3k/month for the appropriate AWS instance.</p>

<p>So yes, that‚Äôs why even though I definitely, totally have $3k to dish out monthly for my LLM pet project, I opted for the slowest, tiniest (but highly recommended) model I could find: GPT4All.</p>

<p>All of this put into perspective the computational power needed for AI on an enterprise scale. And when you think about companies training models on the entire internet‚Äôs worth of data, the scale is truly mind-boggling.</p>

<h2 id="what-this-project-taught-me">What This Project Taught Me</h2>

<h3 id="1-the-infrastructure-reality">1. The Infrastructure Reality</h3>
<p>Running even a small LLM gave me deep appreciation for the engineering challenges at scale. Meaning that optimization is no joke.</p>

<h3 id="2-the-experimentation-framework">2. The Experimentation Framework</h3>
<p>In an ideal world, I would have loved to deploy dozens of different models and built dashboards comparing cost, speed, accuracy, and specialization. (I know those dashboards exist somewhere and still would love to see them. üëÄ)</p>

<h3 id="3-its-time-to-demystify-ai">3. It‚Äôs Time to Demystify AI</h3>
<p>There‚Äôs a lot of misunderstanding around what AI is as a technology. In order for more people to have a say in how AI shapes our world, there needs to be more readily available, accurate information about what it is and how it works. There‚Äôs a need to demystify AI because it‚Äôs here whether we like it or not. It‚Äôs actually crucial for more people to understand how AI works because of the sheer magnitude with which it‚Äôs affecting our world. It‚Äôs changing our daily interactions, our work, and ultimately it‚Äôs reshaping the entire economy in ways we haven‚Äôt fully felt yet.</p>

<p>The comparison to the assembly line or steam engine isn‚Äôt hyperbole. While the full consequences aren‚Äôt visible yet, the transformation is already underway. Understanding how these systems work, their limitations, and how they can be changed, isn‚Äôt just a question of technical curiosity, it‚Äôs a collective necessity.</p>

<h3 id="4-creative-engineering-exists">4. Creative Engineering Exists</h3>
<p>I‚Äôve always been drawn to the creative aspects of engineering: the problem-solving, the elegant solutions, the way good infrastructure feels like art. In my opinion, AI expands that human creative potential ‚Äì because its power comes from human creativity and work in the first place. The question becomes ‚Äì like with any epoch-shaping technology ‚Äì who has oversight and calls the shots on how AI is used at the end of the day?</p>

<h2 id="the-rip-van-winkle-effect">The Rip Van Winkle Effect</h2>
<h4 id="is-that-a-dated-reference-besides-in-the-obvious-way">(Is that a dated reference? Besides in the obvious way.)</h4>
<p>This has been a fascinating time-skip back into tech. Missing the initial AI explosion and returning to discover a self-coding VSCode has been eye-opening to say the least.</p>

<p>I think AI is an incredible breakthrough with massive both creative and destructive potential. The direction it goes will be determined by who controls it in the future on a massive scale. I think the more people who learn about AI, demystify AI, and imagine ways to use it as a tool for collective good, the better off we all will be.</p>

<p>Understanding AI doesn‚Äôt just mean understanding the math behind it or its technical functionality, but also means understanding the wide-reaching social impacts it has and will have in many aspects of life. Imagining the future of AI isn‚Äôt a responsibility reserved for just MLOps engineers and researchers, this is something everyone has a stake in.</p>

<p>The future feels wide open, and I‚Äôm eager to keep learning ‚Äì about LLMs, about infrastructure, and about the meeting point of creativity and automation. There‚Äôs something energizing about being back in tech during such a transformative moment.</p>

<p>So even if my LLM API is so slow that it hurts, it‚Äôs reminded me that understanding these systems isn‚Äôt optional anymore. It‚Äôs part of playing an active role in the world we‚Äôre all building.</p>

    </div>
</div>
</body>
</html>