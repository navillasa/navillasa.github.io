<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-08-19T06:45:40-04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Natalie Villasana</title><subtitle>DevOps Engineer | navillasa.dev</subtitle><author><name>Natalie Villasana</name><email>navillasa.dev@gmail.com</email></author><entry><title type="html">Building Production-Grade Infrastructure for a Simple App</title><link href="http://localhost:4000/blog/tv-hub-project-overview/" rel="alternate" type="text/html" title="Building Production-Grade Infrastructure for a Simple App" /><published>2025-08-19T00:00:00-04:00</published><updated>2025-08-19T00:00:00-04:00</updated><id>http://localhost:4000/blog/tv-hub-project-overview</id><content type="html" xml:base="http://localhost:4000/blog/tv-hub-project-overview/">&lt;h2 id=&quot;the-paradox-of-portfolio-projects&quot;&gt;The Paradox of Portfolio Projects&lt;/h2&gt;

&lt;p&gt;I faced a classic engineering dilemma: &lt;strong&gt;build something complex that needs sophisticated infrastructure, or build something simple and add sophisticated infrastructure anyway?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;After cycling through ideas (distributed microservices, ML pipelines, IoT dashboards) I kept returning to one idea: a TV show aggregator. Because it was an app with some appeal and usefulness beyond demonstrating its own tech stack. The app itself is straightforward: fetch trending shows from TMDB and TVmaze APIs, rank by popularity, display in a clean interface.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;But there’s a twist.&lt;/strong&gt; I deployed it with enterprise-grade DevOps practices that would typically serve a team of a 50+ engineers. Or at least a dozen.&lt;/p&gt;

&lt;h2 id=&quot;strategic-design-decisions&quot;&gt;Strategic Design Decisions&lt;/h2&gt;

&lt;h3 id=&quot;simple-app-complex-infrastructure&quot;&gt;&lt;strong&gt;Simple App, Complex Infrastructure&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;I specifically chose a simple application to isolate and focus on infrastructure complexity. Here’s why this approach worked:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cognitive Load Management&lt;/strong&gt;: Managing ArgoCD, Vault integration, and Prometheus monitoring is challenging enough without debugging distributed system race conditions simultaneously.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Clear Separation of Concerns&lt;/strong&gt;: When something breaks, I can immediately identify whether it’s an application bug (less likely, given the simplicity) or an infrastructure configuration issue (very likely, given the learning curve).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Real-World Simulation&lt;/strong&gt;: Most production systems start simple and grow complex. This project demonstrates the infrastructure foundation that scales.&lt;/p&gt;

&lt;h2 id=&quot;technical-architecture&quot;&gt;Technical Architecture&lt;/h2&gt;

&lt;p&gt;The application architecture is intentionally minimal:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;React Frontend ←→ Node.js API ←→ PostgreSQL ←→ External APIs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;strong&gt;infrastructure architecture&lt;/strong&gt; tells a different story:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GitHub → Actions → GCR → ArgoCD → GKE Autopilot
    ↓                        ↓
Terraform → GCP Resources   Vault → External Secrets → K8s Secrets
    ↓                        ↓
Monitoring ← Prometheus ← Applications → Logs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;production-grade-components&quot;&gt;&lt;strong&gt;Production-Grade Components&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;GitOps with ArgoCD&lt;/strong&gt;: Declarative deployments with dev/staging/prod environment promotion. Changes flow through Git, not &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kubectl apply&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Infrastructure as Code&lt;/strong&gt;: Terraform manages GKE clusters, static IPs, DNS records, and IAM policies.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Secrets Management&lt;/strong&gt;: HashiCorp Vault with External Secrets Operator. API keys and database credentials never touch Git or container images.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Multi-Environment Overlays&lt;/strong&gt;: Kustomize overlays handle environment-specific configurations. Production can use different resource limits, replica counts, and ingress rules than development.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Observability Stack&lt;/strong&gt;: Prometheus metrics collection with Grafana dashboards. Custom application metrics track API response times and cache hit rates.&lt;/p&gt;

&lt;h2 id=&quot;what-i-learned&quot;&gt;What I Learned&lt;/h2&gt;

&lt;h3 id=&quot;1-mental-model-clarity&quot;&gt;&lt;strong&gt;1. Mental Model Clarity&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Complex infrastructure demands clear mental models. When ArgoCD shows “OutOfSync” status, I need to immediately understand:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Which Git commit should be deployed?&lt;/li&gt;
  &lt;li&gt;What Kustomize transformations apply?&lt;/li&gt;
  &lt;li&gt;How do external secrets affect pod startup?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Practical Impact&lt;/strong&gt;: Reduced debugging time from hours to minutes by maintaining clear architectural diagrams and understanding component dependencies.&lt;/p&gt;

&lt;h3 id=&quot;2-architectural-trade-offs&quot;&gt;&lt;strong&gt;2. Architectural Trade-offs&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Every decision has implications. For example: &lt;a href=&quot;/blog/vault-gitops/&quot;&gt;Vault as ArgoCD Application&lt;/a&gt; explores why I kept secrets management outside GitOps workflows.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Key Trade-off&lt;/strong&gt;: GitOps consistency vs. bootstrap complexity. Pure GitOps purists would manage Vault through ArgoCD, but circular dependencies make this operationally complex.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Decision Framework&lt;/strong&gt;: Evaluate based on operational simplicity, recovery scenarios, and production patterns, not theoretical purity.&lt;/p&gt;

&lt;h3 id=&quot;3-systematic-debugging&quot;&gt;&lt;strong&gt;3. Systematic Debugging&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Production systems fail in creative ways. In &lt;a href=&quot;/blog/debugging-502-errors/&quot;&gt;The Cluster Doctor&lt;/a&gt; blog post I demonstrate my approach to systematic troubleshooting.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Core Principle&lt;/strong&gt;: Most failures are configuration mismatches, not infrastructure failures. Port conflicts, service discovery issues, and protocol mismatches accounted for the vast majority of my deployment problems.&lt;/p&gt;

&lt;h2 id=&quot;why-this-approach-works&quot;&gt;Why This Approach Works&lt;/h2&gt;

&lt;h3 id=&quot;for-learning&quot;&gt;&lt;strong&gt;For Learning&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Starting with a simple application let me focus on infrastructure concepts without application complexity interference. I could experiment with GitOps workflows, monitoring configurations, and security policies without worrying about business logic bugs. For the most part :)&lt;/p&gt;

&lt;h3 id=&quot;for-demonstrating&quot;&gt;&lt;strong&gt;For Demonstrating&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Systems Thinking&lt;/strong&gt;: Understanding how components interact across multiple layers (application, orchestration, infrastructure, security).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Production Readiness&lt;/strong&gt;: Moving beyond “it works on my machine” to “it works reliably in production with proper monitoring, security, and deployment practices.”&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Technology Integration&lt;/strong&gt;: Connecting multiple tools (ArgoCD, Vault, Prometheus, Terraform) into cohesive workflows rather than using them in isolation.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Decision Making&lt;/strong&gt;: Choosing appropriate architectural patterns based on trade-offs. A lot more fun, and difficult, than following tutorials.&lt;/p&gt;

&lt;h2 id=&quot;current-status&quot;&gt;Current Status&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;http://tv-hub.navillasa.dev&quot;&gt;Live application&lt;/a&gt; with full GitOps deployment, multi-environment promotion, and comprehensive monitoring.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Next Phases&lt;/strong&gt;: Cost optimization dashboard, Redis caching layer, and advanced alerting rules.&lt;/p&gt;

&lt;h2 id=&quot;the-meta-learning&quot;&gt;The Meta-Learning&lt;/h2&gt;

&lt;p&gt;This project demonstrates that I can build production-ready infrastructure, make informed architectural decisions, and systematically debug complex systems.&lt;/p&gt;

&lt;p&gt;More than learning how to use individual tools, I learned how they integrate, &lt;em&gt;when&lt;/em&gt; to use them, and what trade-offs each decision creates.&lt;/p&gt;

&lt;p&gt;Building infrastructure for a simple application taught me more about production DevOps than building a complex application with simple deployment ever could.&lt;/p&gt;</content><author><name>Natalie Villasana</name></author><category term="devops" /><category term="kubernetes" /><category term="architecture" /><category term="kubernetes" /><category term="argocd" /><category term="terraform" /><category term="gitops" /><category term="gke" /><category term="portfolio" /><summary type="html">The Paradox of Portfolio Projects</summary></entry><entry><title type="html">The Cluster Doctor, or How I Learned to Stop Worrying and Debug 502s</title><link href="http://localhost:4000/blog/debugging-502-errors/" rel="alternate" type="text/html" title="The Cluster Doctor, or How I Learned to Stop Worrying and Debug 502s" /><published>2025-08-18T00:00:00-04:00</published><updated>2025-08-18T00:00:00-04:00</updated><id>http://localhost:4000/blog/debugging-502-errors</id><content type="html" xml:base="http://localhost:4000/blog/debugging-502-errors/">## The Problem Pattern

Throughout this project, I've hit the same type of issue repeatedly:
- **Frontend** looking for `dev-backend-service` instead of `prod-backend-service`
- **ArgoCD ingress** using port 443 instead of port 80
- **Vault** connection errors due to service discovery issues
- **External Secrets** pointing to wrong Vault paths

**The common thread**: 502 Bad Gateway errors caused by communication mismatches.

## The 502 Error: What It Really Means

```
502 Bad Gateway = &quot;I can reach something, but it's not responding correctly&quot;
```

**This is different from:**
- **404**: &quot;I can't find anything at this path&quot;
- **503**: &quot;Service is temporarily unavailable&quot;  
- **Connection timeout**: &quot;I can't reach anything at all&quot;

**502 specifically means**: The proxy/load balancer reached a backend, but the backend response was invalid.

## The Systematic Debugging Approach

### Step 1: Identify the Communication Chain

Every 502 has a path like this:
```
Client → Load Balancer → Service → Pod
```

Find where it breaks by checking each link.

### Step 2: Check Backend Health in Load Balancer

```bash
# Get detailed ingress status
kubectl describe ingress &lt;ingress-name&gt; -n &lt;namespace&gt;

# Look for backend health status
# Example output:
ingress.kubernetes.io/backends: {
  &quot;k8s1-backend-service-443&quot;:&quot;UNHEALTHY&quot;  # ← The smoking gun!
}
```

**Key indicators:**
- `UNHEALTHY` = Backend isn't responding on expected port/protocol
- `HEALTHY` = Backend is fine, look elsewhere

## Pro Tips for Faster Debugging

### 1. **Use Port-Forward for Direct Testing**
```bash
# Bypass ingress/service and test pod directly
kubectl port-forward pod/&lt;pod-name&gt; 8080:8080
curl http://localhost:8080/health
```

### 2. **Check Multiple Namespaces**
```bash
# Service in wrong namespace is super common
kubectl get services --all-namespaces | grep &lt;service-name&gt;
```

The key insight: Most 502 errors are configuration mismatches, not infrastructure failures. A systematic approach beats random troubleshooting every time.</content><author><name>Natalie Villasana</name></author><category term="kubernetes" /><category term="debugging" /><category term="devops" /><category term="kubernetes" /><category term="502-errors" /><category term="troubleshooting" /><category term="nginx" /><category term="ingress" /><summary type="html">The Problem Pattern</summary></entry><entry><title type="html">Why I Didn’t Make Vault an ArgoCD Application</title><link href="http://localhost:4000/blog/vault-gitops/" rel="alternate" type="text/html" title="Why I Didn’t Make Vault an ArgoCD Application" /><published>2025-08-18T00:00:00-04:00</published><updated>2025-08-18T00:00:00-04:00</updated><id>http://localhost:4000/blog/vault-gitops</id><content type="html" xml:base="http://localhost:4000/blog/vault-gitops/">## The Question

During the GitOps implementation, I considered whether HashiCorp Vault should be managed as an ArgoCD application alongside the other workloads. This post explains why I chose to keep Vault outside of the GitOps workflow.

## The Temptation

At first glance, managing Vault through ArgoCD seems _pretty_ cool:

- **Consistency**: Everything else is managed by ArgoCD
- **Version Control**: Vault configuration tracked in Git
- **Declarative**: Infrastructure as Code principles
- **Automation**: Automated deployments and updates

## The Bootstrap Problem

The fundamental issue is a **circular dependency**:

```
┌─────────────┐    needs    ┌──────────────────┐    needs    ┌───────────┐
│   ArgoCD    │ ──────────► │ External Secrets │ ──────────► │   Vault   │
│             │             │    Operator      │             │           │
└─────────────┘             └──────────────────┘             └───────────┘
       ▲                                                            │
       │                    manages (if GitOps)                     │
       └────────────────────────────────────────────────────────────┘
```

**The problem**: If ArgoCD manages Vault, then ArgoCD depends on Vault (for secrets) which depends on ArgoCD (for deployment). This creates an unresolvable bootstrap dependency.

## Infrastructure Layers

I solved this by establishing clear **infrastructure layers**:

### Layer 0: Foundation Infrastructure
- **GKE Cluster** (Terraform)
- **Static IPs** (Terraform)
- **Vault** (kubectl apply)
- **External Secrets Operator** (Helm)

### Layer 1: GitOps Platform
- **ArgoCD** (kubectl apply)
- **ClusterSecretStore** (ArgoCD)

### Layer 2: Applications
- **tv-dashboard-dev** (ArgoCD)
- **tv-dashboard-prod** (ArgoCD)
- **monitoring-stack** (ArgoCD)

## Alternative Approaches Considered

### 1. Manual Sync Only
```yaml
# vault-app.yaml
spec:
  syncPolicy:
    automated: null  # No auto-sync to avoid bootstrap issues
```

**Pros**: Vault config in Git  
**Cons**: Manual intervention required, defeats GitOps automation

### 2. App-of-Apps Pattern
```yaml
# bootstrap-app.yaml - deployed manually
# Manages vault-app.yaml and argocd-apps.yaml
```

**Pros**: Complete GitOps coverage  
**Cons**: Complex bootstrap sequence, harder to debug

### 3. External Vault
Use a managed secret service (Google Secret Manager, AWS Secrets Manager)

**Pros**: No bootstrap problem, less operational overhead  
**Cons**: Vendor lock-in, less learning value for this project

## The Decision: Keep Vault Outside GitOps

**Reasons**:

1. **Operational Simplicity**: Vault is foundational infrastructure that should be stable and simple to manage
2. **Recovery Scenarios**: If ArgoCD fails, we can still access Vault to recover secrets
3. **Bootstrap Clarity**: Clear separation between foundation and application layers
4. **Production Patterns**: Many organizations treat secret management as Layer 0 infrastructure

## Production Considerations

In production environments, you might see:

### At Large Organizations
- **Dedicated Vault clusters** managed by platform teams
- **Vault-as-a-Service** provided to application teams
- **Manual deployment** with infrastructure automation (Terraform)

### At Cloud-Native Shops
- **Managed secret services** (AWS Secrets Manager, etc.)
- **External Secrets Operator** connecting to cloud providers
- **No self-hosted Vault** at all

### In GitOps Purist Repos
- **Everything in Git** including Vault
- **Complex bootstrap procedures** with operator dependencies
- **Acceptance of operational complexity** for consistency

## Key Takeaway

**Not everything needs to be in GitOps.** The right architectural boundary depends on:

- **Operational complexity** vs **consistency benefits**
- **Bootstrap dependencies** and **recovery scenarios**  
- **Team structure** and **operational expertise**
- **Compliance requirements** and **audit trails**

For my TV Dashboard project, keeping Vault as foundational infrastructure provided the right balance of simplicity and functionality while still demonstrating modern secret management practices.

## What I Learned

1. **Architectural boundaries matter** - not every tool fits every pattern
2. **Bootstrap dependencies** are real constraints in system design
3. **Operational simplicity** often trumps theoretical consistency
4. **Production patterns** should inform learning project decisions

The goal isn't to GitOps-ify everything — it's to build systems that are **reliable, maintainable, and appropriate for their context**.

---

*This decision reflects my specific context and learning goals. Your environment may have different constraints and requirements.*</content><author><name>Natalie Villasana</name></author><category term="kubernetes" /><category term="vault" /><category term="gitops" /><category term="argocd" /><category term="devops" /><category term="kubernetes" /><category term="vault" /><category term="gitops" /><category term="argocd" /><category term="devops" /><category term="design" /><summary type="html">The Question</summary></entry></feed>